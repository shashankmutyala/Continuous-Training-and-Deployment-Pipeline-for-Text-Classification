# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mtL4S18xRa0OL_9lMtAkazV5LxC0_ZsR
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install transformers pandas numpy torch scikit-learn mlflow flask pyngrok
# !pip install flask flask-ngrok

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import torch
import time
from torch.utils.data import Dataset
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
import mlflow
from flask import Flask, request, jsonify
import threading
from pyngrok import ngrok
import smtplib
from email.mime.text import MIMEText
from sklearn.preprocessing import LabelEncoder

# Constants for monitoring
STALENESS_THRESHOLD = 0.85
EMAIL_ALERT_RECIPIENT = 'something09@gmail.com'

# Define Dataset class (using DataLoader)
class TextDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

# Define Pipeline class
class TextClassificationPipeline:
    def __init__(self, model_name="distilbert-base-uncased", num_labels=2):
        self.model_name = model_name
        self.num_labels = num_labels
        self.tokenizer = BertTokenizer.from_pretrained(model_name)
        self.model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)

        # Use MlflowClient instead of setting tracking URI directly
        self.mlflow_client = MlflowClient()
        self.mlflow_client.set_experiment("text_classification")

    def monitor_model(self, eval_data, monitoring_interval=86400):  # Check every 24 hours
        while True:
            time.sleep(monitoring_interval)
            current_eval_results = self.evaluate_model(eval_data)
            if current_eval_results['eval_accuracy'] < STALENESS_THRESHOLD:
                self.send_alert("Model performance degraded. Retraining required.")
                self.retrain_model()

    def evaluate_model(self, eval_data):
        eval_dataloader = DataLoader(eval_data, batch_size=16)  # Use DataLoader
        trainer = Trainer(model=self.model)
        eval_results = trainer.evaluate(eval_dataset=eval_dataloader)
        return eval_results

    def load_and_preprocess_data(self, df, text_column, label_column, test_size=0.2):
        le = LabelEncoder()
        df[label_column] = le.fit_transform(df[label_column])
        train_df, test_df = train_test_split(df, test_size=test_size, stratify=df[label_column], random_state=42)
        train_dataset = TextDataset(train_df[text_column].tolist(), train_df[label_column].tolist(), self.tokenizer)
        test_dataset = TextDataset(test_df[text_column].tolist(), test_df[label_column].tolist(), self.tokenizer)
        self.label_encoder = le
        return train_dataset, test_dataset

    def train_model(self, train_dataset, test_dataset):
        training_args = TrainingArguments(
            output_dir="/content/drive/MyDrive/model_checkpoints",
            evaluation_strategy="steps",
            eval_steps=1500,
            learning_rate=1e-5,
            per_device_train_batch_size=16,
            per_device_eval_batch_size=16,
            num_train_epochs=3,
            weight_decay=0.01,
            logging_dir="./logs",
            logging_steps=1500,
            save_strategy="steps",
            save_steps=1500,
            load_best_model_at_end=True,
            metric_for_best_model="accuracy"
        )

        def compute_metrics(eval_pred):
            predictions, labels = eval_pred
            if isinstance(predictions, np.ndarray):
                predictions = torch.from_numpy(predictions)
            predictions = torch.argmax(predictions, axis=1)
            accuracy = accuracy_score(labels, predictions.numpy())
            f1 = f1_score(labels, predictions.numpy(), average='weighted')
            return {"accuracy": accuracy, "f1": f1}

        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=test_dataset,
            compute_metrics=compute_metrics
        )

        with self.mlflow_client.start_run():
            self.mlflow_client.log_params({
                "model_name": self.model_name,
                "learning_rate": training_args.learning_rate,
                "batch_size": training_args.per_device_train_batch_size,
                "epochs": training_args.num_train_epochs
            })
            trainer.train()
            eval_results = trainer.evaluate()
            self.mlflow_client.log_metrics({
                "eval_accuracy": eval_results["eval_accuracy"],
                "eval_f1": eval_results["eval_f1"]
            })
            model_path = "/content/drive/MyDrive/models/current"
            self.model.save_pretrained(model_path)
            self.tokenizer.save_pretrained(model_path)
            return eval_results

    def send_alert(self, message):
        msg = MIMEText(message)
        msg['Subject'] = 'Model Staleness Alert'
        msg['From'] = 'something09@gmail.com'
        msg['To'] = EMAIL_ALERT_RECIPIENT
        with smtplib.SMTP('smtp.gmail.com', 587) as server:
            server.starttls()
            server.login('something094@gmail.com', 'Something@09') #Set the email for alert
            server.send_message(msg)

    def predict_batch(self, texts):
        inputs = self.tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors="pt").to(self.device)
        with torch.no_grad():
            outputs = self.model(**inputs)
            predictions = torch.softmax(outputs.logits, dim=1)
        return predictions.cpu().numpy()

    def retrain_model(self):
        self.train_model(train_dataset, test_dataset)

# Load and prepare dataset
df = pd.read_csv('/content/IMDB Dataset.csv')
print("Dataset Info:")
print(df.info())
print("\nFirst few rows:")
print(df.head())

# Initialize pipeline
pipeline = TextClassificationPipeline(num_labels=2)
train_dataset, test_dataset = pipeline.load_and_preprocess_data(df, 'review', 'sentiment')

# Train and evaluate the model
eval_results = pipeline.train_model(train_dataset, test_dataset)

# Print the evaluation results
print("Evaluation Results:", eval_results)

# Flask app setup
app = Flask(__name__)

@app.route('/')
def home():
    return "Welcome to the Text Classification API!"

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    prediction = pipeline.predict_batch(data['text'])[0]
    response = {f'class_{i}_probability': float(prob) for i, prob in enumerate(prediction)}
    return jsonify(response)

if __name__ == '__main__':
    app.run(debug=True)
get_ipython().system_raw("FLASK_APP=app.py flask run --host=0.0.0.0 --port=5000 &")

ngrok.set_auth_token('2o3PYG33Gc32nvAFaXs6pchkXet_7eeV9FYsg4NZbRoUU6uZ1')
public_url = ngrok.connect(5000)
print(f' * Public URL: {public_url}')

# Run Flask app
if __name__ == "__main__":
    get_ipython().system_raw("FLASK_APP=app.py flask run --host=0.0.0.0 --port=5000 &")
    app.run(port=5000)